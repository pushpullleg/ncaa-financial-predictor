{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà 04. Trajectory Feature Engineering (Adjusted for Data Size)\n",
    "\n",
    "## Objective\n",
    "Transform the raw NCAA EADA data into a **Trajectory Classification** dataset.\n",
    "\n",
    "## Constraint Satisfaction\n",
    "**Requirement:** >10,000 rows.\n",
    "**Strategy:** Use **2-year trends** (past) and **1-year forecast** (future). \n",
    "*   Loss: 2 years (lag) + 1 year (target) = 3 years lost.\n",
    "*   Remaining: 7 years * 1,722 institutions ‚âà 12,000 rows. (Safe > 10k)\n",
    "\n",
    "## Target Variable: `Financial_Trajectory`\n",
    "We define the trajectory over the **next 1 year**:\n",
    "1.  **Improving:** Revenue Growth > 3% AND Expense Growth < Revenue Growth\n",
    "2.  **Declining:** Revenue Growth < 0% OR Expense Growth > Revenue Growth + 3%\n",
    "3.  **Stable:** Everything else\n",
    "\n",
    "## Input\n",
    "*   `../initial files/Output_10yrs_reported_schools_17220.csv`\n",
    "\n",
    "## Output\n",
    "*   `trajectory_ml_ready.csv`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T16:20:55.052057Z",
     "iopub.status.busy": "2025-11-20T16:20:55.051808Z",
     "iopub.status.idle": "2025-11-20T16:20:57.369701Z",
     "shell.execute_reply": "2025-11-20T16:20:57.369224Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-23T22:11:02.270104Z",
     "start_time": "2025-11-23T22:11:02.267189Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T16:20:57.405284Z",
     "iopub.status.busy": "2025-11-20T16:20:57.405019Z",
     "iopub.status.idle": "2025-11-20T16:20:57.963603Z",
     "shell.execute_reply": "2025-11-20T16:20:57.963179Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-23T22:11:23.680649Z",
     "start_time": "2025-11-23T22:11:23.140343Z"
    }
   },
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    # Path based on user's directory structure\n",
    "    df = pd.read_csv('../../initial files/Output_10yrs_reported_schools_17220.csv')\n",
    "except FileNotFoundError:\n",
    "    # Fallback for safety\n",
    "    df = pd.read_csv('Output_10yrs_reported_schools_17220.csv')\n",
    "\n",
    "# Rename columns for easier reference\n",
    "df = df.rename(columns={\n",
    "    'Survey Year': 'Year',\n",
    "    'Institution Name': 'Institution_Name',\n",
    "    'State CD': 'State',\n",
    "    'Classification Name': 'Classification_Name'\n",
    "})\n",
    "\n",
    "# Sort by Institution and Year to ensure correct lag calculations\n",
    "df = df.sort_values(['UNITID', 'Year']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Years: {df['Year'].min()} - {df['Year'].max()}\")\n",
    "print(f\"Institutions: {df['UNITID'].nunique()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (17220, 580)\n",
      "Years: 2014 - 2023\n",
      "Institutions: 1722\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T16:20:57.966753Z",
     "iopub.status.busy": "2025-11-20T16:20:57.966580Z",
     "iopub.status.idle": "2025-11-20T16:20:57.972597Z",
     "shell.execute_reply": "2025-11-20T16:20:57.972284Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-23T22:11:26.865137Z",
     "start_time": "2025-11-23T22:11:26.856516Z"
    }
   },
   "source": [
    "# 1. Handle Missing Values in Key Financials\n",
    "financial_cols = ['Grand Total Revenue', 'Grand Total Expenses']\n",
    "for col in financial_cols:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "# 2. Create Total Participation Column\n",
    "df['Total_Athletes'] = df[\"Unduplicated Count Men's Participation\"].fillna(0) + df[\"Unduplicated Count Women's Participation\"].fillna(0)\n",
    "\n",
    "# 3. Create Efficiency Ratio (Revenue / Expenses)\n",
    "# Avoid division by zero\n",
    "df['Efficiency_Ratio'] = df['Grand Total Revenue'] / df['Grand Total Expenses'].replace(0, 1)\n",
    "\n",
    "# 4. Flag \"Exactly 1.0\" Reporters (Accounting Manipulation)\n",
    "df['Reports_Exactly_One'] = (df['Efficiency_Ratio'] == 1.0).astype(int)\n",
    "\n",
    "print(\"‚úÖ Data cleaned and basic metrics created\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data cleaned and basic metrics created\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering: 2-Year Trends\n",
    "We calculate trends over the *past* 2 years ($t, t-1$). This saves 1 year of data compared to 3-year trends."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T16:20:57.974538Z",
     "iopub.status.busy": "2025-11-20T16:20:57.974385Z",
     "iopub.status.idle": "2025-11-20T16:20:58.914727Z",
     "shell.execute_reply": "2025-11-20T16:20:58.914263Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-23T22:11:31.579403Z",
     "start_time": "2025-11-23T22:11:30.742655Z"
    }
   },
   "source": [
    "# Group by UNITID to process each institution separately\n",
    "grouped = df.groupby('UNITID')\n",
    "\n",
    "# --- A. Growth Rates (1-year and 2-year CAGR) ---\n",
    "# 1-year growth (t vs t-1)\n",
    "df['Revenue_Growth_1yr'] = grouped['Grand Total Revenue'].pct_change()\n",
    "df['Expense_Growth_1yr'] = grouped['Grand Total Expenses'].pct_change()\n",
    "\n",
    "# 2-year CAGR (t vs t-2)\n",
    "df['Revenue_CAGR_2yr'] = (grouped['Grand Total Revenue'].shift(0) / grouped['Grand Total Revenue'].shift(2))**(1/2) - 1\n",
    "df['Expense_CAGR_2yr'] = (grouped['Grand Total Expenses'].shift(0) / grouped['Grand Total Expenses'].shift(2))**(1/2) - 1\n",
    "\n",
    "# --- B. Rolling Averages (2-year) ---\n",
    "df['Revenue_Mean_2yr'] = grouped['Grand Total Revenue'].transform(lambda x: x.rolling(window=2).mean())\n",
    "df['Expense_Mean_2yr'] = grouped['Grand Total Expenses'].transform(lambda x: x.rolling(window=2).mean())\n",
    "df['Efficiency_Mean_2yr'] = grouped['Efficiency_Ratio'].transform(lambda x: x.rolling(window=2).mean())\n",
    "\n",
    "# --- C. Volatility (Standard Deviation over 3 years - still useful if available, else 2) ---\n",
    "# We'll use 2-year std dev to be consistent with saving rows\n",
    "df['Revenue_Volatility_2yr'] = grouped['Grand Total Revenue'].transform(lambda x: x.rolling(window=2).std())\n",
    "df['Expense_Volatility_2yr'] = grouped['Grand Total Expenses'].transform(lambda x: x.rolling(window=2).std())\n",
    "\n",
    "# --- D. Structural Features ---\n",
    "# Division (Extract from Classification Name)\n",
    "def extract_division(class_name):\n",
    "    if pd.isna(class_name): return 'Unknown'\n",
    "    if 'NCAA Division I' in class_name: return 'D1'\n",
    "    if 'NCAA Division II' in class_name: return 'D2'\n",
    "    if 'NCAA Division III' in class_name: return 'D3'\n",
    "    return 'Other'\n",
    "\n",
    "df['Division'] = df['Classification_Name'].apply(extract_division)\n",
    "\n",
    "print(\"‚úÖ Feature engineering complete\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Feature engineering complete\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Generation: `Financial_Trajectory` (1-Year Lookahead)\n",
    "We define the target for year $t$ based on what happens in year $t+1$.\n",
    "This saves another year of data compared to 2-year lookahead."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T16:20:58.916960Z",
     "iopub.status.busy": "2025-11-20T16:20:58.916788Z",
     "iopub.status.idle": "2025-11-20T16:20:59.260227Z",
     "shell.execute_reply": "2025-11-20T16:20:59.259795Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-23T22:11:42.041841Z",
     "start_time": "2025-11-23T22:11:41.802018Z"
    }
   },
   "source": [
    "# Calculate Future Growth (Next 1 year)\n",
    "future_window = 1\n",
    "\n",
    "# Future Revenue Growth (t to t+1)\n",
    "df['Future_Revenue_Growth'] = grouped['Grand Total Revenue'].shift(-future_window) / grouped['Grand Total Revenue'].shift(0) - 1\n",
    "\n",
    "# Future Expense Growth (t to t+1)\n",
    "df['Future_Expense_Growth'] = grouped['Grand Total Expenses'].shift(-future_window) / grouped['Grand Total Expenses'].shift(0) - 1\n",
    "\n",
    "# Define Trajectory Class\n",
    "def define_trajectory(row):\n",
    "    rev_growth = row['Future_Revenue_Growth']\n",
    "    exp_growth = row['Future_Expense_Growth']\n",
    "    \n",
    "    if pd.isna(rev_growth) or pd.isna(exp_growth):\n",
    "        return np.nan\n",
    "    \n",
    "    # IMPROVING: Healthy revenue growth AND expenses growing slower than revenue\n",
    "    # Threshold lowered to 3% since it's a 1-year window\n",
    "    if (rev_growth > 0.03) and (exp_growth < rev_growth):\n",
    "        return 'Improving'\n",
    "    \n",
    "    # DECLINING: Shrinking revenue OR expenses growing out of control\n",
    "    elif (rev_growth < 0.00) or (exp_growth > rev_growth + 0.03):\n",
    "        return 'Declining'\n",
    "    \n",
    "    # STABLE: Everything else\n",
    "    else:\n",
    "        return 'Stable'\n",
    "\n",
    "df['Target_Trajectory'] = df.apply(define_trajectory, axis=1)\n",
    "\n",
    "# Map to integers for ML (0=Declining, 1=Stable, 2=Improving)\n",
    "trajectory_map = {'Declining': 0, 'Stable': 1, 'Improving': 2}\n",
    "df['Target_Label'] = df['Target_Trajectory'].map(trajectory_map)\n",
    "\n",
    "print(\"‚úÖ Target variable created\")\n",
    "print(df['Target_Trajectory'].value_counts(normalize=True))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Target variable created\n",
      "Target_Trajectory\n",
      "Stable       0.484772\n",
      "Declining    0.374823\n",
      "Improving    0.140405\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Cleanup & Save\n",
    "Remove rows with missing features (first 2 years) or missing targets (last 1 year)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T16:20:59.262481Z",
     "iopub.status.busy": "2025-11-20T16:20:59.262283Z",
     "iopub.status.idle": "2025-11-20T16:20:59.483606Z",
     "shell.execute_reply": "2025-11-20T16:20:59.483252Z"
    },
    "ExecuteTime": {
     "end_time": "2025-11-23T22:11:48.169874Z",
     "start_time": "2025-11-23T22:11:47.982369Z"
    }
   },
   "source": [
    "# Filter usable data\n",
    "# Must have valid features (2-year lag requires starting from year 3 of data)\n",
    "# Must have valid target (requires looking ahead 1 year)\n",
    "\n",
    "df_ml = df.dropna(subset=['Revenue_CAGR_2yr', 'Target_Label']).copy()\n",
    "\n",
    "# Select columns for modeling\n",
    "feature_cols = [\n",
    "    'UNITID', 'Institution_Name', 'Year', 'State', 'Division', # Identifiers\n",
    "    'Grand Total Revenue', 'Grand Total Expenses', 'Total_Athletes', # Raw values\n",
    "    'Revenue_Growth_1yr', 'Expense_Growth_1yr', # 1-yr trends\n",
    "    'Revenue_CAGR_2yr', 'Expense_CAGR_2yr', # 2-yr trends\n",
    "    'Revenue_Mean_2yr', 'Expense_Mean_2yr', 'Efficiency_Mean_2yr', # 2-yr averages\n",
    "    'Revenue_Volatility_2yr', 'Expense_Volatility_2yr', # Volatility\n",
    "    'Reports_Exactly_One', # Data quality flag\n",
    "    'Target_Trajectory', 'Target_Label' # Targets\n",
    "]\n",
    "\n",
    "df_final = df_ml[feature_cols]\n",
    "\n",
    "print(f\"Final Dataset Shape: {df_final.shape}\")\n",
    "print(f\"Years Included: {df_final['Year'].min()} - {df_final['Year'].max()}\")\n",
    "\n",
    "# Verify constraint\n",
    "if len(df_final) > 10000:\n",
    "    print(f\"‚úÖ Constraint Met: {len(df_final)} rows > 10,000\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Constraint Warning: {len(df_final)} rows < 10,000\")\n",
    "\n",
    "# Save to CSV\n",
    "output_path = 'trajectory_ml_ready.csv'\n",
    "df_final.to_csv(output_path, index=False)\n",
    "print(f\"‚úÖ Saved to {output_path}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset Shape: (12054, 20)\n",
      "Years Included: 2016 - 2022\n",
      "‚úÖ Constraint Met: 12054 rows > 10,000\n",
      "‚úÖ Saved to trajectory_ml_ready.csv\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
