{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Data Preparation\n",
    "\n",
    "## Objective\n",
    "Prepare the NCAA financial data for Time-Series Deep Learning (LSTM). We need to create sequences of financial data for schools that have 10 years of consistent reporting.\n",
    "\n",
    "## Strategy\n",
    "1.  **Load Raw Data**: Use the full 10-year dataset.\n",
    "2.  **Filter Schools**: Keep only schools with 10 consecutive years of data.\n",
    "3.  **Feature Engineering**: Calculate key financial metrics per year.\n",
    "4.  **Sequence Creation**: Create sliding windows (e.g., use years 1-5 to predict year 6).\n",
    "5.  **Save**: Export as numpy arrays for LSTM training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:13:23.078155Z",
     "iopub.status.busy": "2025-11-20T18:13:23.078061Z",
     "iopub.status.idle": "2025-11-20T18:13:24.644763Z",
     "shell.execute_reply": "2025-11-20T18:13:24.644371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Loaded.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:13:24.674957Z",
     "iopub.status.busy": "2025-11-20T18:13:24.674725Z",
     "iopub.status.idle": "2025-11-20T18:13:25.014002Z",
     "shell.execute_reply": "2025-11-20T18:13:25.013728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data Shape: (17220, 580)\n",
      "\n",
      "Columns: ['Survey Year', 'UNITID', 'OPE ID', 'Institution Name', 'State CD', 'Classification Name', 'Classification Other', 'Sanction Code', 'Sanction Name', 'Male Undergraduates', 'Female Undergraduates', 'Total Undergraduates', \"Archery Men's Team Participation\", \"Archery Women's Team Participation\", 'Archery Coed Team Men Participation', 'Archery Coed Team Women Participation', 'Archery Total Participation', \"Badminton Women's Team Participation\", 'Badminton Total Participation', \"Baseball Men's Team Participation\"]...\n",
      "\n",
      "Year Range: 2014 - 2023\n"
     ]
    }
   ],
   "source": [
    "# Load the raw 10-year dataset\n",
    "df = pd.read_csv('../initial files/Output_10yrs_reported_schools_17220.csv')\n",
    "\n",
    "print(f\"Raw Data Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()[:20]}...\")  # Show first 20 columns\n",
    "print(f\"\\nYear Range: {df['Survey Year'].min()} - {df['Survey Year'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select Key Financial Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:13:25.015685Z",
     "iopub.status.busy": "2025-11-20T18:13:25.015577Z",
     "iopub.status.idle": "2025-11-20T18:13:25.030973Z",
     "shell.execute_reply": "2025-11-20T18:13:25.030708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue columns: ['Grand Total Revenue']\n",
      "Expense columns: ['Grand Total Expenses']\n",
      "\n",
      "Cleaned Data Shape: (17220, 10)\n"
     ]
    }
   ],
   "source": [
    "# Find the revenue and expense columns\n",
    "revenue_cols = [c for c in df.columns if 'Grand Total Revenue' in c]\n",
    "expense_cols = [c for c in df.columns if 'Grand Total Expenses' in c]\n",
    "\n",
    "print(f\"Revenue columns: {revenue_cols}\")\n",
    "print(f\"Expense columns: {expense_cols}\")\n",
    "\n",
    "# Select core columns\n",
    "core_cols = ['Survey Year', 'UNITID', 'Institution Name', 'State CD', 'Classification Name']\n",
    "core_cols.extend(revenue_cols)\n",
    "core_cols.extend(expense_cols)\n",
    "\n",
    "# Add athlete counts\n",
    "athlete_cols = [c for c in df.columns if 'Undergraduates' in c]\n",
    "core_cols.extend(athlete_cols)\n",
    "\n",
    "df_clean = df[core_cols].copy()\n",
    "df_clean = df_clean.rename(columns={'Survey Year': 'Year'})\n",
    "\n",
    "print(f\"\\nCleaned Data Shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter Schools with 10 Years of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:13:25.032807Z",
     "iopub.status.busy": "2025-11-20T18:13:25.032703Z",
     "iopub.status.idle": "2025-11-20T18:13:25.052032Z",
     "shell.execute_reply": "2025-11-20T18:13:25.051760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schools with exactly 10 years of data: 1722\n",
      "LSTM Dataset Shape: (17220, 10)\n",
      "Total Schools: 1722\n"
     ]
    }
   ],
   "source": [
    "# Count years per school\n",
    "school_years = df_clean.groupby('UNITID')['Year'].nunique()\n",
    "schools_with_10_years = school_years[school_years == 10].index\n",
    "\n",
    "print(f\"Schools with exactly 10 years of data: {len(schools_with_10_years)}\")\n",
    "\n",
    "# Filter to only these schools\n",
    "df_lstm = df_clean[df_clean['UNITID'].isin(schools_with_10_years)].copy()\n",
    "df_lstm = df_lstm.sort_values(['UNITID', 'Year'])\n",
    "\n",
    "print(f\"LSTM Dataset Shape: {df_lstm.shape}\")\n",
    "print(f\"Total Schools: {df_lstm['UNITID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:13:25.053628Z",
     "iopub.status.busy": "2025-11-20T18:13:25.053539Z",
     "iopub.status.idle": "2025-11-20T18:13:25.138176Z",
     "shell.execute_reply": "2025-11-20T18:13:25.137893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Engineered.\n",
      "\n",
      "Feature columns: ['Revenue', 'Expenses', 'Efficiency_Ratio', 'Net_Income', 'Revenue_Growth', 'Expense_Growth']\n"
     ]
    }
   ],
   "source": [
    "# Get the actual column names for revenue and expenses\n",
    "rev_col = [c for c in df_lstm.columns if 'Grand Total Revenue' in c][0]\n",
    "exp_col = [c for c in df_lstm.columns if 'Grand Total Expenses' in c][0]\n",
    "\n",
    "# Calculate basic features\n",
    "df_lstm['Revenue'] = pd.to_numeric(df_lstm[rev_col], errors='coerce')\n",
    "df_lstm['Expenses'] = pd.to_numeric(df_lstm[exp_col], errors='coerce')\n",
    "df_lstm['Efficiency_Ratio'] = df_lstm['Revenue'] / df_lstm['Expenses']\n",
    "df_lstm['Net_Income'] = df_lstm['Revenue'] - df_lstm['Expenses']\n",
    "\n",
    "# Calculate year-over-year growth\n",
    "df_lstm['Revenue_Growth'] = df_lstm.groupby('UNITID')['Revenue'].pct_change()\n",
    "df_lstm['Expense_Growth'] = df_lstm.groupby('UNITID')['Expenses'].pct_change()\n",
    "\n",
    "# Fill NaN values\n",
    "df_lstm = df_lstm.fillna(0)\n",
    "\n",
    "# Replace inf values\n",
    "df_lstm = df_lstm.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(\"Features Engineered.\")\n",
    "print(f\"\\nFeature columns: {['Revenue', 'Expenses', 'Efficiency_Ratio', 'Net_Income', 'Revenue_Growth', 'Expense_Growth']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Target Variable (Future Trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:13:25.140334Z",
     "iopub.status.busy": "2025-11-20T18:13:25.139926Z",
     "iopub.status.idle": "2025-11-20T18:13:25.263440Z",
     "shell.execute_reply": "2025-11-20T18:13:25.263134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Distribution:\n",
      "Target\n",
      "1.0    7513\n",
      "0.0    5809\n",
      "2.0    2176\n",
      "Name: count, dtype: int64\n",
      "\n",
      "0=Declining, 1=Stable, 2=Improving\n"
     ]
    }
   ],
   "source": [
    "# Calculate future growth (1 year ahead)\n",
    "df_lstm['Future_Rev_Growth'] = df_lstm.groupby('UNITID')['Revenue_Growth'].shift(-1)\n",
    "df_lstm['Future_Exp_Growth'] = df_lstm.groupby('UNITID')['Expense_Growth'].shift(-1)\n",
    "\n",
    "# Define trajectory based on future growth\n",
    "def classify_trajectory(row):\n",
    "    if pd.isna(row['Future_Rev_Growth']):\n",
    "        return np.nan\n",
    "    \n",
    "    # Improving: Revenue growing >3% AND expenses growing slower than revenue\n",
    "    if row['Future_Rev_Growth'] > 0.03 and row['Future_Exp_Growth'] < row['Future_Rev_Growth']:\n",
    "        return 2  # Improving\n",
    "    # Declining: Revenue shrinking OR expenses growing >3% faster than revenue\n",
    "    elif row['Future_Rev_Growth'] < 0.0 or row['Future_Exp_Growth'] > (row['Future_Rev_Growth'] + 0.03):\n",
    "        return 0  # Declining\n",
    "    else:\n",
    "        return 1  # Stable\n",
    "\n",
    "df_lstm['Target'] = df_lstm.apply(classify_trajectory, axis=1)\n",
    "\n",
    "# Remove rows without target (last year for each school)\n",
    "df_lstm = df_lstm.dropna(subset=['Target'])\n",
    "\n",
    "print(f\"\\nTarget Distribution:\")\n",
    "print(df_lstm['Target'].value_counts())\n",
    "print(f\"\\n0=Declining, 1=Stable, 2=Improving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Sequences for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:13:25.264940Z",
     "iopub.status.busy": "2025-11-20T18:13:25.264836Z",
     "iopub.status.idle": "2025-11-20T18:13:25.724148Z",
     "shell.execute_reply": "2025-11-20T18:13:25.723878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sequence Shape: (6888, 5, 6)\n",
      "  - Samples: 6888\n",
      "  - Time Steps: 5\n",
      "  - Features: 6\n",
      "\n",
      "Target Shape: (6888,)\n",
      "\n",
      "Target Distribution in Sequences:\n",
      "  Class 0: 2594 (37.7%)\n",
      "  Class 1: 3322 (48.2%)\n",
      "  Class 2: 972 (14.1%)\n"
     ]
    }
   ],
   "source": [
    "# Define sequence parameters\n",
    "SEQUENCE_LENGTH = 5  # Use 5 years of history\n",
    "\n",
    "# Select features for the model\n",
    "feature_cols = ['Revenue', 'Expenses', 'Efficiency_Ratio', 'Net_Income', 'Revenue_Growth', 'Expense_Growth']\n",
    "\n",
    "# Normalize features (LSTM is sensitive to scale)\n",
    "scaler = StandardScaler()\n",
    "df_lstm[feature_cols] = scaler.fit_transform(df_lstm[feature_cols])\n",
    "\n",
    "# Create sequences\n",
    "X_sequences = []\n",
    "y_sequences = []\n",
    "school_ids = []\n",
    "\n",
    "for school_id in df_lstm['UNITID'].unique():\n",
    "    school_data = df_lstm[df_lstm['UNITID'] == school_id]\n",
    "    \n",
    "    # Need at least SEQUENCE_LENGTH years\n",
    "    if len(school_data) < SEQUENCE_LENGTH:\n",
    "        continue\n",
    "    \n",
    "    # Extract features and targets\n",
    "    features = school_data[feature_cols].values\n",
    "    targets = school_data['Target'].values\n",
    "    \n",
    "    # Create sliding windows\n",
    "    for i in range(len(school_data) - SEQUENCE_LENGTH):\n",
    "        X_sequences.append(features[i:i+SEQUENCE_LENGTH])\n",
    "        y_sequences.append(targets[i+SEQUENCE_LENGTH])  # Predict the next year\n",
    "        school_ids.append(school_id)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X_sequences)\n",
    "y = np.array(y_sequences)\n",
    "\n",
    "print(f\"\\nSequence Shape: {X.shape}\")\n",
    "print(f\"  - Samples: {X.shape[0]}\")\n",
    "print(f\"  - Time Steps: {X.shape[1]}\")\n",
    "print(f\"  - Features: {X.shape[2]}\")\n",
    "print(f\"\\nTarget Shape: {y.shape}\")\n",
    "print(f\"\\nTarget Distribution in Sequences:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  Class {int(label)}: {count} ({count/len(y)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Data for LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-20T18:13:25.725607Z",
     "iopub.status.busy": "2025-11-20T18:13:25.725501Z",
     "iopub.status.idle": "2025-11-20T18:13:25.729305Z",
     "shell.execute_reply": "2025-11-20T18:13:25.729053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved to 'lstm_data.npz'\n",
      "Ready for LSTM training with 6888 sequences!\n"
     ]
    }
   ],
   "source": [
    "# Save the sequences\n",
    "np.savez('lstm_data.npz', \n",
    "         X=X, \n",
    "         y=y, \n",
    "         feature_names=feature_cols,\n",
    "         school_ids=school_ids)\n",
    "\n",
    "print(\"\\nData saved to 'lstm_data.npz'\")\n",
    "print(f\"Ready for LSTM training with {X.shape[0]} sequences!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
