{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# LSTM Model for Financial Trajectory Prediction\n",
                "\n",
                "## Objective\n",
                "Build and train an LSTM (Long Short-Term Memory) neural network to predict NCAA athletic department financial trajectories using sequential data.\n",
                "\n",
                "## Why LSTM?\n",
                "Unlike traditional ML models (XGBoost, Random Forest) that treat each year independently, LSTM can:\n",
                "- **Remember patterns** across multiple years\n",
                "- **Detect trends** (e.g., \"3 years of slow decline often leads to crisis\")\n",
                "- **Handle temporal dependencies** naturally\n",
                "\n",
                "## Comparison Goal\n",
                "Our XGBoost model achieved **ROC-AUC = 0.70**. Can LSTM beat it?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ModuleNotFoundError",
                    "evalue": "No module named 'tensorflow'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix, roc_auc_score\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m layers\n",
                        "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "from tensorflow.keras import layers\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "\n",
                "# Set random seeds for reproducibility\n",
                "np.random.seed(42)\n",
                "tf.random.set_seed(42)\n",
                "\n",
                "print(f\"TensorFlow Version: {tf.__version__}\")\n",
                "print(\"Libraries Loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Prepared Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loaded Data:\n",
                        "  X shape: (6888, 5, 6) (samples, time_steps, features)\n",
                        "  y shape: (6888,)\n",
                        "  Features: ['Revenue' 'Expenses' 'Efficiency_Ratio' 'Net_Income' 'Revenue_Growth'\n",
                        " 'Expense_Growth']\n",
                        "\n",
                        "Class Distribution:\n",
                        "  Class 0: 2594 (37.7%)\n",
                        "  Class 1: 3322 (48.2%)\n",
                        "  Class 2: 972 (14.1%)\n"
                    ]
                }
            ],
            "source": [
                "# Load the sequences we created\n",
                "data = np.load('lstm_data.npz', allow_pickle=True)\n",
                "X = data['X']\n",
                "y = data['y']\n",
                "feature_names = data['feature_names']\n",
                "\n",
                "print(f\"Loaded Data:\")\n",
                "print(f\"  X shape: {X.shape} (samples, time_steps, features)\")\n",
                "print(f\"  y shape: {y.shape}\")\n",
                "print(f\"  Features: {feature_names}\")\n",
                "print(f\"\\nClass Distribution:\")\n",
                "unique, counts = np.unique(y, return_counts=True)\n",
                "for label, count in zip(unique, counts):\n",
                "    print(f\"  Class {int(label)}: {count} ({count/len(y)*100:.1f}%)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Train-Test Split"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'to_categorical' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Convert labels to categorical (one-hot encoding for neural network)\u001b[39;00m\n\u001b[32m      7\u001b[39m num_classes = \u001b[38;5;28mlen\u001b[39m(np.unique(y))\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m y_train_cat = \u001b[43mto_categorical\u001b[49m(y_train, num_classes=num_classes)\n\u001b[32m      9\u001b[39m y_test_cat = to_categorical(y_test, num_classes=num_classes)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining Set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m samples\u001b[39m\u001b[33m\"\u001b[39m)\n",
                        "\u001b[31mNameError\u001b[39m: name 'to_categorical' is not defined"
                    ]
                }
            ],
            "source": [
                "# Split the data\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "# Convert labels to categorical (one-hot encoding for neural network)\n",
                "num_classes = len(np.unique(y))\n",
                "y_train_cat = to_categorical(y_train, num_classes=num_classes)\n",
                "y_test_cat = to_categorical(y_test, num_classes=num_classes)\n",
                "\n",
                "print(f\"Training Set: {X_train.shape[0]} samples\")\n",
                "print(f\"Test Set: {X_test.shape[0]} samples\")\n",
                "print(f\"Number of Classes: {num_classes}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Build LSTM Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model architecture\n",
                "model = keras.Sequential([\n",
                "    # First LSTM layer with dropout for regularization\n",
                "    layers.LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
                "    layers.Dropout(0.3),\n",
                "    \n",
                "    # Second LSTM layer\n",
                "    layers.LSTM(32, return_sequences=False),\n",
                "    layers.Dropout(0.3),\n",
                "    \n",
                "    # Dense layers\n",
                "    layers.Dense(32, activation='relu'),\n",
                "    layers.Dropout(0.2),\n",
                "    \n",
                "    # Output layer (3 classes: Declining, Stable, Improving)\n",
                "    layers.Dense(num_classes, activation='softmax')\n",
                "])\n",
                "\n",
                "# Compile the model\n",
                "model.compile(\n",
                "    optimizer='adam',\n",
                "    loss='categorical_crossentropy',\n",
                "    metrics=['accuracy']\n",
                ")\n",
                "\n",
                "print(\"Model Architecture:\")\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Train the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Early stopping to prevent overfitting\n",
                "early_stop = keras.callbacks.EarlyStopping(\n",
                "    monitor='val_loss',\n",
                "    patience=10,\n",
                "    restore_best_weights=True\n",
                ")\n",
                "\n",
                "# Train the model\n",
                "history = model.fit(\n",
                "    X_train, y_train_cat,\n",
                "    epochs=50,\n",
                "    batch_size=32,\n",
                "    validation_split=0.2,\n",
                "    callbacks=[early_stop],\n",
                "    verbose=1\n",
                ")\n",
                "\n",
                "print(\"\\nTraining Complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Visualize Training History"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot training history\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Loss\n",
                "ax1.plot(history.history['loss'], label='Training Loss')\n",
                "ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
                "ax1.set_xlabel('Epoch')\n",
                "ax1.set_ylabel('Loss')\n",
                "ax1.set_title('Model Loss')\n",
                "ax1.legend()\n",
                "ax1.grid(True)\n",
                "\n",
                "# Accuracy\n",
                "ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
                "ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
                "ax2.set_xlabel('Epoch')\n",
                "ax2.set_ylabel('Accuracy')\n",
                "ax2.set_title('Model Accuracy')\n",
                "ax2.legend()\n",
                "ax2.grid(True)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluate on Test Set"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions\n",
                "y_pred_proba = model.predict(X_test)\n",
                "y_pred = np.argmax(y_pred_proba, axis=1)\n",
                "\n",
                "# Classification Report\n",
                "print(\"=\" * 60)\n",
                "print(\"LSTM MODEL PERFORMANCE\")\n",
                "print(\"=\" * 60)\n",
                "print(\"\\nClassification Report:\")\n",
                "print(classification_report(y_test, y_pred, target_names=['Declining', 'Stable', 'Improving']))\n",
                "\n",
                "# ROC-AUC Score\n",
                "try:\n",
                "    roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr')\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"ROC-AUC Score: {roc_auc:.4f}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    print(f\"\\nComparison to XGBoost (0.70): {'+' if roc_auc > 0.70 else ''}{(roc_auc - 0.70):.4f}\")\n",
                "except:\n",
                "    print(\"Could not calculate ROC-AUC\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Confusion Matrix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot confusion matrix\n",
                "cm = confusion_matrix(y_test, y_pred)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
                "            xticklabels=['Declining', 'Stable', 'Improving'],\n",
                "            yticklabels=['Declining', 'Stable', 'Improving'])\n",
                "plt.xlabel('Predicted')\n",
                "plt.ylabel('Actual')\n",
                "plt.title('Confusion Matrix - LSTM Model')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Save the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the trained model\n",
                "model.save('lstm_trajectory_model.h5')\n",
                "print(\"Model saved to 'lstm_trajectory_model.h5'\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Final Comparison Summary"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate final metrics\n",
                "from sklearn.metrics import accuracy_score, f1_score\n",
                "\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
                "\n",
                "print(\"\\n\" + \"=\"*60)\n",
                "print(\"FINAL RESULTS COMPARISON\")\n",
                "print(\"=\"*60)\n",
                "print(f\"\\nLSTM Model:\")\n",
                "print(f\"  - Accuracy: {accuracy:.4f}\")\n",
                "print(f\"  - Macro F1-Score: {f1_macro:.4f}\")\n",
                "print(f\"  - ROC-AUC: {roc_auc:.4f}\")\n",
                "print(f\"\\nXGBoost Baseline:\")\n",
                "print(f\"  - ROC-AUC: 0.7000\")\n",
                "print(f\"\\nConclusion:\")\n",
                "if roc_auc > 0.70:\n",
                "    print(f\"  ✓ LSTM WINS! (+{(roc_auc - 0.70):.4f} improvement)\")\n",
                "    print(f\"  The sequential nature of the data benefits from LSTM's memory.\")\n",
                "else:\n",
                "    print(f\"  ✗ XGBoost still better ({(0.70 - roc_auc):.4f} difference)\")\n",
                "    print(f\"  Possible reasons: Limited data, or financial trajectories are more\")\n",
                "    print(f\"  dependent on recent snapshots than long-term patterns.\")\n",
                "print(\"=\"*60)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
