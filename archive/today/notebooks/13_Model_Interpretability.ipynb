{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 13. Model Interpretability (SHAP Analysis)\n",
                "\n",
                "## Objective\n",
                "Understand *why* the XGBoost model makes specific predictions using SHAP (SHapley Additive exPlanations) values.\n",
                "\n",
                "## Inputs\n",
                "- `trajectory_ml_ready_advanced.csv`\n",
                "\n",
                "## Analysis Steps\n",
                "1.  **Retrain Best Model**: Use the optimized hyperparameters found in Step 11.\n",
                "2.  **Global Importance**: Summary plot of feature impact.\n",
                "3.  **Local Interpretability**: Explain individual predictions (e.g., why was School X predicted to Decline?).\n",
                "4.  **Dependence Plots**: Visualize non-linear relationships."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import shap\n",
                "from sklearn.model_selection import train_test_split\n",
                "from xgboost import XGBClassifier\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "# Set plot style\n",
                "sns.set(style=\"whitegrid\")\n",
                "shap.initjs()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data & Retrain Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.read_csv('trajectory_ml_ready_advanced.csv')\n",
                "\n",
                "# Drop identifiers\n",
                "drop_cols = ['UNITID', 'Institution_Name', 'Year', 'Target_Trajectory', 'Target_Label', 'State']\n",
                "X = df.drop(columns=drop_cols)\n",
                "y = df['Target_Label']\n",
                "\n",
                "# Encode categorical variables\n",
                "X = pd.get_dummies(X, columns=['Division'], drop_first=True)\n",
                "\n",
                "# Train-Test Split\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
                "\n",
                "# Apply SMOTE (only on training data)\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
                "\n",
                "# Best Hyperparameters from Step 11\n",
                "best_params = {\n",
                "    'n_estimators': 300,\n",
                "    'max_depth': 3,\n",
                "    'learning_rate': 0.05,\n",
                "    'subsample': 0.7,\n",
                "    'colsample_bytree': 0.9,\n",
                "    'min_child_weight': 3,\n",
                "    'use_label_encoder': False,\n",
                "    'eval_metric': 'mlogloss',\n",
                "    'random_state': 42\n",
                "}\n",
                "\n",
                "model = XGBClassifier(**best_params)\n",
                "model.fit(X_train_resampled, y_train_resampled)\n",
                "\n",
                "print(\"Model Retrained Successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Calculate SHAP Values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create object that can calculate shap values\n",
                "explainer = shap.TreeExplainer(model)\n",
                "\n",
                "# Calculate shap values. This is what we will plot.\n",
                "# We'll use a sample of the test set to speed up calculation if needed, but here dataset is small enough.\n",
                "shap_values = explainer.shap_values(X_test)\n",
                "\n",
                "print(f\"SHAP Values Shape: {np.array(shap_values).shape}\")\n",
                "# Shape should be (n_classes, n_samples, n_features)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Global Feature Importance (Summary Plot)\n",
                "This plot shows which features are most important for each class.\n",
                "- Class 0: Declining\n",
                "- Class 1: Stable\n",
                "- Class 2: Improving"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class_names = ['Declining', 'Stable', 'Improving']\n",
                "\n",
                "# Summary plot for all classes\n",
                "plt.figure(figsize=(12, 8))\n",
                "shap.summary_plot(shap_values, X_test, class_names=class_names, plot_type=\"bar\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Detailed Summary Plot (Class 0: Declining)\n",
                "Let's look specifically at what drives a school to be classified as **Declining**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 8))\n",
                "shap.summary_plot(shap_values[0], X_test, plot_type=\"dot\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Interpretation:**\n",
                "- **High values** (red) of `Efficiency_Mean_2yr` (Revenue/Expense) have a **negative** impact on the \"Declining\" prediction (pushing it towards Stable/Improving).\n",
                "- **Low values** (blue) of `Efficiency_Mean_2yr` increase the risk of Declining.\n",
                "- This confirms our intuition: Inefficiency leads to decline."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Dependence Plot\n",
                "Let's see the interaction between `Efficiency_Mean_2yr` and `Total_Athletes`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "shap.dependence_plot(\"Efficiency_Mean_2yr\", shap_values[0], X_test, interaction_index=\"Total_Athletes\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}